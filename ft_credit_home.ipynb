{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPutO6NRhKXeeKtK3FiXJY/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annisafitribas/ft_credit_home/blob/main/ft_credit_home.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PERSIAPAN**"
      ],
      "metadata": {
        "id": "umI9UgB3954B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aMX0d0T9Ib5",
        "outputId": "5595bf69-72ec-4ba8-8fe3-1bc8e606e5cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WORKDIR: /content/home_credit_task\n"
          ]
        }
      ],
      "source": [
        "import os, sys, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "WORKDIR = '/content/home_credit_task'\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "print(\"WORKDIR:\", WORKDIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bertujuan untuk menyiapkan folder kerja dan library yang akan digunakan dalam proses pengolahan data"
      ],
      "metadata": {
        "id": "vsPmvAGV-Ndf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependencies if missing (Colab-friendly)\n",
        "try:\n",
        "    import gdown\n",
        "except Exception:\n",
        "    !pip install -q gdown\n",
        "    import gdown\n",
        "\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "except Exception:\n",
        "    !pip install -q lightgbm\n",
        "    import lightgbm as lgb\n",
        "\n",
        "try:\n",
        "    from pptx import Presentation\n",
        "    from pptx.util import Inches, Pt\n",
        "except Exception:\n",
        "    !pip install -q python-pptx\n",
        "    from pptx import Presentation\n",
        "    from pptx.util import Inches, Pt\n",
        "\n",
        "try:\n",
        "    import matplotlib\n",
        "    import matplotlib.pyplot as plt\n",
        "except Exception:\n",
        "    !pip install -q matplotlib\n",
        "    import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK0xVTgcDaRl",
        "outputId": "c6647050-7d69-44ba-809f-f17fab34fba1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/472.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m471.0/472.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/175.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn / joblib\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "rayBHCRZEIwo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Download dataset file"
      ],
      "metadata": {
        "id": "jQZRCZGJEP8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = {\n",
        "    'application_train.csv': '1q059QolR6CNxB0PWESAjkEWIprNutajA',\n",
        "    'application_test.csv' : '1QD7ehk_hzXze0vHQuYa5qyqfDcfI8Sex',\n",
        "    'bureau.csv'           : '1hndizX1t5ab0DTnKMTedqVJ1ZxLVclhF',\n",
        "    'bureau_balance.csv'   : '1OXEQb_L6S_mZALJi4--C6RyFI6yOsq4x',\n",
        "    'credit_card_balance.csv': '1t6Hhsmj0vSCCKUlNXht_xDQ6Z6l4M0Vu',\n",
        "    'installments_payments.csv': '126xrKCW5EQrxkQoDwmN-yb00ILBKnhR8',\n",
        "    'POS_CASH_balance.csv' : '1dODAmBQLaylpM2JcCHfc4KNbbtKY7xhA',\n",
        "    'previous_application.csv': '1D4O7xf-lF_3oBeu6XMwzhpXtSvhcgoBU',\n",
        "    'HomeCredit_columns_description.csv': '1v2iGGOJjlUGSTsQz-bsjtjtyM5IQp7uW',\n",
        "    'sample_submission.csv': '1JongVA9fWMYml5XKVnbhm8TUlR5Efs0n'\n",
        "}\n",
        "\n",
        "for fname, fid in files.items():\n",
        "    dest = os.path.join(WORKDIR, fname)\n",
        "    if not os.path.exists(dest):\n",
        "        print(\"Downloading\", fname)\n",
        "        url = f\"https://drive.google.com/uc?export=download&id={fid}\"\n",
        "        gdown.download(url, dest, quiet=False)\n",
        "    else:\n",
        "        print(\"Exists:\", fname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyUxC7z_ERaB",
        "outputId": "bd97c71e-a20e-47c1-e9ee-aa90d734de7b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading application_train.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=1q059QolR6CNxB0PWESAjkEWIprNutajA\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=1q059QolR6CNxB0PWESAjkEWIprNutajA&confirm=t&uuid=25d94ba2-580e-4722-9845-3773dec0d1a0\n",
            "To: /content/home_credit_task/application_train.csv\n",
            "100%|██████████| 166M/166M [00:02<00:00, 72.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading application_test.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1QD7ehk_hzXze0vHQuYa5qyqfDcfI8Sex\n",
            "To: /content/home_credit_task/application_test.csv\n",
            "100%|██████████| 26.6M/26.6M [00:00<00:00, 48.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading bureau.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=1hndizX1t5ab0DTnKMTedqVJ1ZxLVclhF\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=1hndizX1t5ab0DTnKMTedqVJ1ZxLVclhF&confirm=t&uuid=fd5b9554-2f13-456d-98ef-610362456f5d\n",
            "To: /content/home_credit_task/bureau.csv\n",
            "100%|██████████| 170M/170M [00:02<00:00, 60.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading bureau_balance.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=1OXEQb_L6S_mZALJi4--C6RyFI6yOsq4x\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=1OXEQb_L6S_mZALJi4--C6RyFI6yOsq4x&confirm=t&uuid=935b25ee-d8e6-4458-9c06-bc5244cad164\n",
            "To: /content/home_credit_task/bureau_balance.csv\n",
            "100%|██████████| 376M/376M [00:05<00:00, 73.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading credit_card_balance.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=1t6Hhsmj0vSCCKUlNXht_xDQ6Z6l4M0Vu\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=1t6Hhsmj0vSCCKUlNXht_xDQ6Z6l4M0Vu&confirm=t&uuid=218e4c45-ebd9-4412-bfb4-d43c25b8c8fa\n",
            "To: /content/home_credit_task/credit_card_balance.csv\n",
            "100%|██████████| 425M/425M [00:07<00:00, 56.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading installments_payments.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=126xrKCW5EQrxkQoDwmN-yb00ILBKnhR8\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=126xrKCW5EQrxkQoDwmN-yb00ILBKnhR8&confirm=t&uuid=ec9a5be1-638f-4d73-8481-ac6fc7eee529\n",
            "To: /content/home_credit_task/installments_payments.csv\n",
            "100%|██████████| 723M/723M [00:08<00:00, 80.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading POS_CASH_balance.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=1dODAmBQLaylpM2JcCHfc4KNbbtKY7xhA\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=1dODAmBQLaylpM2JcCHfc4KNbbtKY7xhA&confirm=t&uuid=334eba1d-79bb-47b2-bf52-023242f20f1e\n",
            "To: /content/home_credit_task/POS_CASH_balance.csv\n",
            "100%|██████████| 393M/393M [00:04<00:00, 81.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading previous_application.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=1D4O7xf-lF_3oBeu6XMwzhpXtSvhcgoBU\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=1D4O7xf-lF_3oBeu6XMwzhpXtSvhcgoBU&confirm=t&uuid=b19155fb-402f-49e2-b498-4ec7a50b2ec6\n",
            "To: /content/home_credit_task/previous_application.csv\n",
            "100%|██████████| 405M/405M [00:05<00:00, 76.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading HomeCredit_columns_description.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1v2iGGOJjlUGSTsQz-bsjtjtyM5IQp7uW\n",
            "To: /content/home_credit_task/HomeCredit_columns_description.csv\n",
            "100%|██████████| 37.4k/37.4k [00:00<00:00, 17.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sample_submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1JongVA9fWMYml5XKVnbhm8TUlR5Efs0n\n",
            "To: /content/home_credit_task/sample_submission.csv\n",
            "100%|██████████| 536k/536k [00:00<00:00, 7.22MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load csv"
      ],
      "metadata": {
        "id": "6DCJ6JlZFS3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLoading CSVs ...\")\n",
        "train = pd.read_csv(os.path.join(WORKDIR, 'application_train.csv'), low_memory=False)\n",
        "test  = pd.read_csv(os.path.join(WORKDIR, 'application_test.csv'), low_memory=False)\n",
        "bureau = pd.read_csv(os.path.join(WORKDIR, 'bureau.csv'), low_memory=False)\n",
        "bureau_balance = pd.read_csv(os.path.join(WORKDIR, 'bureau_balance.csv'), low_memory=False)\n",
        "credit_card_balance = pd.read_csv(os.path.join(WORKDIR, 'credit_card_balance.csv'), low_memory=False)\n",
        "installments = pd.read_csv(os.path.join(WORKDIR, 'installments_payments.csv'), low_memory=False)\n",
        "pos_cash = pd.read_csv(os.path.join(WORKDIR, 'POS_CASH_balance.csv'), low_memory=False)\n",
        "prev_app = pd.read_csv(os.path.join(WORKDIR, 'previous_application.csv'), low_memory=False)\n",
        "sample_sub = pd.read_csv(os.path.join(WORKDIR, 'sample_submission.csv'), low_memory=False)\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"train\", train.shape, \"test\", test.shape)\n",
        "print(\"bureau\", bureau.shape, \"bureau_balance\", bureau_balance.shape)\n",
        "print(\"credit_card_balance\", credit_card_balance.shape, \"installments\", installments.shape)\n",
        "print(\"pos_cash\", pos_cash.shape, \"previous_application\", prev_app.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVB95BsjFU4b",
        "outputId": "6b0f6543-41ca-4fb5-f770-e1de169d274e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading CSVs ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Quick EDA & visuals**"
      ],
      "metadata": {
        "id": "BulJn6uOFytA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- TARGET distribution ---\")\n",
        "print(train['TARGET'].value_counts(normalize=True))\n",
        "\n",
        "# helper for saving plots\n",
        "def savefig(fig, filename):\n",
        "    path = os.path.join(WORKDIR, filename)\n",
        "    fig.savefig(path, bbox_inches='tight')\n",
        "    print('Saved plot:', path)"
      ],
      "metadata": {
        "id": "7AyuhCOzF3pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 target distribution plot"
      ],
      "metadata": {
        "id": "xL2ibvHTGJb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(6,4))\n",
        "ax = fig.add_subplot(111)\n",
        "counts = train['TARGET'].value_counts().sort_index()\n",
        "ax.bar(counts.index.astype(str), counts.values)\n",
        "ax.set_title('Target distribution (counts)')\n",
        "ax.set_xlabel('TARGET')\n",
        "ax.set_ylabel('Count')\n",
        "savefig(fig, 'target_distribution.png')\n",
        "plt.close(fig)"
      ],
      "metadata": {
        "id": "mHWzu0v1GOJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 top missing features (bar)"
      ],
      "metadata": {
        "id": "-ve5l0wJGSfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing = train.isna().mean().sort_values(ascending=False).head(30)\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.barh(missing.index[::-1], missing.values[::-1])\n",
        "ax.set_title('Top missing percentage (train)')\n",
        "ax.set_xlabel('Fraction missing')\n",
        "savefig(fig, 'missing_pct_top.png')\n",
        "plt.close(fig)"
      ],
      "metadata": {
        "id": "O_Y1HbtmGVXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 correlation heatmap of numeric features (sampled for speed)"
      ],
      "metadata": {
        "id": "vMhKs1a2GbDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num = train.select_dtypes(include=[np.number]).drop(['SK_ID_CURR','TARGET'], axis=1, errors='ignore')\n",
        "# sample columns to avoid huge matrix\n",
        "num_small = num.sample(n=min(30, num.shape[1]), axis=1)\n",
        "corr = num_small.corr()\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.imshow(corr.values, interpolation='nearest')\n",
        "ax.set_xticks(np.arange(len(corr.columns)))\n",
        "ax.set_xticklabels(corr.columns, rotation=90, fontsize=8)\n",
        "ax.set_yticks(np.arange(len(corr.columns)))\n",
        "ax.set_yticklabels(corr.columns, fontsize=8)\n",
        "ax.set_title('Correlation matrix (subset)')\n",
        "fig.colorbar(cax, ax=ax)\n",
        "savefig(fig, 'corr_matrix_subset.png')\n",
        "plt.close(fig)"
      ],
      "metadata": {
        "id": "fPenjorDGcTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Feature engineering (same as baseline but kept clear)**"
      ],
      "metadata": {
        "id": "dtpmxTA4G0Db"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Aggregations dari bureau (per SK_ID_CURR)"
      ],
      "metadata": {
        "id": "Q_-IvaliH23G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b_agg = bureau.groupby('SK_ID_CURR').agg(\n",
        "    bureau_loans_count = ('SK_ID_BUREAU', 'count'),\n",
        "    bureau_credit_sum_mean = ('AMT_CREDIT_SUM', 'mean'),\n",
        "    bureau_credit_sum_max = ('AMT_CREDIT_SUM', 'max'),\n",
        "    bureau_active_cnt = ('CREDIT_ACTIVE', lambda x: (x=='Active').sum())\n",
        ").reset_index()"
      ],
      "metadata": {
        "id": "k7yFPghbH7jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 bureau_balance -> bad rate per bureau id then agg"
      ],
      "metadata": {
        "id": "R3kVXLfqH_i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bb_bad = bureau_balance[bureau_balance['STATUS'].isin(['2','3','4','5'])].groupby('SK_ID_BUREAU').size().rename('bad_months')\n",
        "bb_tot = bureau_balance.groupby('SK_ID_BUREAU').size().rename('total_months')\n",
        "bb = pd.concat([bb_bad, bb_tot], axis=1).fillna(0)\n",
        "bb['bad_rate'] = bb['bad_months'] / bb['total_months']\n",
        "bureau2 = bureau.merge(bb.reset_index(), on='SK_ID_BUREAU', how='left')\n",
        "b2_agg = bureau2.groupby('SK_ID_CURR').agg(\n",
        "    bureau_prev_bad_rate_mean = ('bad_rate','mean'),\n",
        "    bureau_prev_months_mean = ('total_months','mean')\n",
        ").reset_index()\n",
        "\n",
        "b_agg = b_agg.merge(b2_agg, on='SK_ID_CURR', how='left')"
      ],
      "metadata": {
        "id": "O93EIi6jH94U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 previous_application aggregates"
      ],
      "metadata": {
        "id": "CnKtbJ-iIERM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prev_agg = prev_app.groupby('SK_ID_CURR').agg(\n",
        "    prev_count = ('SK_ID_PREV','count'),\n",
        "    prev_amt_app_mean = ('AMT_APPLICATION','mean'),\n",
        "    prev_amt_credit_mean = ('AMT_CREDIT','mean'),\n",
        "    prev_approved = ('NAME_CONTRACT_STATUS', lambda x: (x=='Approved').sum())\n",
        ").reset_index()"
      ],
      "metadata": {
        "id": "6SoR84nKILR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## # 4.4 installments"
      ],
      "metadata": {
        "id": "hBX_nHR8IOmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inst_agg = installments.groupby('SK_ID_CURR').agg(\n",
        "    inst_count = ('NUM_INSTALMENT_VERSION','count'),\n",
        "    inst_amt_sum = ('AMT_PAYMENT','sum'),\n",
        "    inst_delay_mean = ('DAYS_ENTRY_PAYMENT', lambda x: np.nanmean(x - installments.loc[x.index,'DAYS_INSTALMENT']))\n",
        ").reset_index()"
      ],
      "metadata": {
        "id": "Gzqa_BwRITGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5 credit_card & pos"
      ],
      "metadata": {
        "id": "yAqhyu60Icll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cc_agg = credit_card_balance.groupby('SK_ID_CURR').agg(\n",
        "    cc_count = ('SK_ID_PREV','count'),\n",
        "    cc_bal_mean = ('AMT_BALANCE','mean'),\n",
        "    cc_limit_mean = ('AMT_CREDIT_LIMIT_ACTUAL','mean')\n",
        ").reset_index()\n",
        "\n",
        "pos_agg = pos_cash.groupby('SK_ID_CURR').agg(\n",
        "    pos_count = ('SK_ID_PREV','count'),\n",
        "    pos_dpd_mean = ('SK_DPD','mean')\n",
        ").reset_index()"
      ],
      "metadata": {
        "id": "1V8pPrw3Ia5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.6 application-level features"
      ],
      "metadata": {
        "id": "4VIG_pLfIigS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_app_features(df):\n",
        "    df = df.copy()\n",
        "    df['DAYS_BIRTH_YEARS'] = (-df['DAYS_BIRTH']) / 365.25\n",
        "    df['DAYS_EMPLOYED_YEARS'] = df['DAYS_EMPLOYED'].replace(365243, np.nan) / -365.25\n",
        "    df['INCOME_CREDIT_RATIO'] = df['AMT_INCOME_TOTAL'] / (df['AMT_CREDIT'] + 1)\n",
        "    df['CREDIT_GOODS_RATIO'] = df['AMT_CREDIT'] / (df['AMT_GOODS_PRICE'] + 1)\n",
        "    return df[['SK_ID_CURR','DAYS_BIRTH_YEARS','DAYS_EMPLOYED_YEARS','AMT_INCOME_TOTAL','AMT_CREDIT','INCOME_CREDIT_RATIO','CREDIT_GOODS_RATIO']]\n",
        "\n",
        "app_train_feats = make_app_features(train)\n",
        "app_test_feats = make_app_features(test)"
      ],
      "metadata": {
        "id": "q70a3-F8IghU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Merge features**"
      ],
      "metadata": {
        "id": "qTD0bxa7I3hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_base = train[['SK_ID_CURR','TARGET']].merge(b_agg, on='SK_ID_CURR', how='left') \\\n",
        "                               .merge(prev_agg, on='SK_ID_CURR', how='left') \\\n",
        "                               .merge(inst_agg, on='SK_ID_CURR', how='left') \\\n",
        "                               .merge(cc_agg, on='SK_ID_CURR', how='left') \\\n",
        "                               .merge(pos_agg, on='SK_ID_CURR', how='left') \\\n",
        "                               .merge(app_train_feats, on='SK_ID_CURR', how='left')\n",
        "\n",
        "test_base = test[['SK_ID_CURR']].merge(b_agg, on='SK_ID_CURR', how='left') \\\n",
        "                               .merge(prev_agg, on='SK_ID_CURR', how='left') \\\n",
        "                               .merge(inst_agg, on='SK_ID_CURR', how='left') \\\n",
        "                               .merge(cc_agg, on='SK_ID_CURR', how='left') \\\n",
        "                               .merge(pos_agg, on='SK_ID_CURR', how='left') \\\n",
        "                               .merge(app_test_feats, on='SK_ID_CURR', how='left')"
      ],
      "metadata": {
        "id": "KY2_5jmUI8JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Prepare X, y; preprocessing**"
      ],
      "metadata": {
        "id": "TGUGA-xCJZJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = train_base['TARGET']\n",
        "X = train_base.drop(['SK_ID_CURR','TARGET'], axis=1)\n",
        "X_test = test_base.drop(['SK_ID_CURR'], axis=1)\n",
        "\n",
        "# numeric / categorical separation\n",
        "num_cols = [c for c in X.columns if X[c].dtype.kind in 'biufc']\n",
        "cat_cols = [c for c in X.columns if c not in num_cols]\n",
        "\n",
        "# Impute numeric with median (computed from train)\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "X[num_cols] = num_imputer.fit_transform(X[num_cols])\n",
        "X_test[num_cols] = num_imputer.transform(X_test[num_cols])\n",
        "\n",
        "# For categorical (if any), fill and label-encode simple\n",
        "for c in cat_cols:\n",
        "    X[c] = X[c].fillna('MISSING').astype(str)\n",
        "    X_test[c] = X_test[c].fillna('MISSING').astype(str)\n",
        "for c in cat_cols:\n",
        "    X[c], _ = pd.factorize(X[c])\n",
        "    X_test[c], _ = pd.factorize(X_test[c])\n",
        "\n",
        "# Ensure X_test has all columns (reindex)\n",
        "X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "print(\"\\nNumber of features:\", X.shape[1])"
      ],
      "metadata": {
        "id": "58N4AXNzJcOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Train/validation split and scaling**"
      ],
      "metadata": {
        "id": "1yBLSC9OJ4Ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr, X_val, y_tr, y_val = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
        "scaler = StandardScaler()\n",
        "X_tr_scaled = scaler.fit_transform(X_tr)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "YlQkb_G0J8eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Logistic Regression**"
      ],
      "metadata": {
        "id": "F3iqq3r3KA3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Logistic Regression ===\")\n",
        "lr = LogisticRegression(max_iter=2000, class_weight='balanced', n_jobs=-1)\n",
        "# 5-fold CV\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "lr_cv_scores = []\n",
        "for tr_idx, vc_idx in kf.split(X, Y):\n",
        "    lr.fit(scaler.fit_transform(X.iloc[tr_idx]), Y.iloc[tr_idx])\n",
        "    p = lr.predict_p#roba(scaler.transform(X.iloc[vc_idx]))[:,1]\n",
        "    lr_cv_scores.append(roc_auc_score(Y.iloc[vc_idx], p))\n",
        "print(\"LR 5-fold AUC: %.5f ± %.5f\" % (np.mean(lr_cv_scores), np.std(lr_cv_scores)))\n",
        "\n",
        "# fit on training partition and validate\n",
        "lr.fit(X_tr_scaled, y_tr)\n",
        "proba_lr_val = lr.predict_proba(X_val_scaled)[:,1]\n",
        "print(\"LR holdout AUC:\", roc_auc_score(y_val, proba_lr_val))\n",
        "print(\"LR classification report (holdout, threshold=0.5):\")\n",
        "print(classification_report(y_val, (proba_lr_val>0.5).astype(int)))\n",
        "\n",
        "# save logistic model & scaler\n",
        "joblib.dump(lr, os.path.join(WORKDIR, 'model_logistic.pkl'))\n",
        "joblib.dump(scaler, os.path.join(WORKDIR, 'scaler_logistic.pkl'))\n",
        "\n",
        "# ROC curve plot (LR)\n",
        "fpr, tpr, _ = roc_curve(y_val, proba_lr_val)\n",
        "roc_auc_lr = auc(fpr, tpr)\n",
        "fig = plt.figure(figsize=(6,5))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(fpr, tpr)\n",
        "ax.plot([0,1],[0,1], linestyle='--')\n",
        "ax.set_title(f'Logistic ROC (AUC={roc_auc_lr:.4f})')\n",
        "ax.set_xlabel('FPR')\n",
        "ax.set_ylabel('TPR')\n",
        "savefig(fig, 'roc_logistic.png')\n",
        "plt.close(fig)"
      ],
      "metadata": {
        "id": "Z9AW9EK9KEBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. LightGBM with RandomizedSearchCV**"
      ],
      "metadata": {
        "id": "UmRclqBGXWyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== LightGBM (RandomizedSearchCV) ===\")\n",
        "from scipy.stats import randint as sp_randint, uniform as sp_uniform\n",
        "\n",
        "lgb_clf = lgb.LGBMClassifier(objective='binary', random_state=42, n_jobs=-1, verbosity=-1)\n",
        "\n",
        "param_dist = {\n",
        "    'num_leaves': [31, 63, 127],\n",
        "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
        "    'n_estimators': [200, 400, 800],\n",
        "    'min_child_samples': [5, 20, 50],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "rs = RandomizedSearchCV(lgb_clf, param_distributions=param_dist, n_iter=12, scoring='roc_auc', cv=3, random_state=42, n_jobs=-1, verbose=1)\n",
        "rs.fit(X, Y)\n",
        "print(\"Best LGB params:\", rs.best_params_)\n",
        "print(\"Best LGB CV score:\", rs.best_score_)\n",
        "\n",
        "best_lgb = rs.best_estimator_\n",
        "# evaluate on holdout\n",
        "best_lgb.fit(X_tr, y_tr)\n",
        "proba_lgb_val = best_lgb.predict_proba(X_val)[:,1]\n",
        "print(\"LGB holdout AUC:\", roc_auc_score(y_val, proba_lgb_val))\n",
        "print(\"LGB classification report (holdout):\")\n",
        "print(classification_report(y_val, (proba_lgb_val>0.5).astype(int)))\n",
        "\n",
        "# Save LGB model\n",
        "joblib.dump(best_lgb, os.path.join(WORKDIR, 'model_lgb.pkl'))\n",
        "\n",
        "# ROC curve plot (LGB)\n",
        "fpr_l, tpr_l, _ = roc_curve(y_val, proba_lgb_val)\n",
        "roc_auc_lgb = auc(fpr_l, tpr_l)\n",
        "fig = plt.figure(figsize=(6,5))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(fpr_l, tpr_l)\n",
        "ax.plot([0,1],[0,1], linestyle='--')\n",
        "ax.set_title(f'LightGBM ROC (AUC={roc_auc_lgb:.4f})')\n",
        "ax.set_xlabel('FPR')\n",
        "ax.set_ylabel('TPR')\n",
        "savefig(fig, 'roc_lgb.png')\n",
        "plt.close(fig)\n",
        "\n",
        "# Combined ROC\n",
        "fig = plt.figure(figsize=(6,5))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(fpr, tpr)\n",
        "ax.plot(fpr_l, tpr_l)\n",
        "ax.plot([0,1],[0,1], linestyle='--')\n",
        "ax.set_title(f'ROC comparison (LR {roc_auc_lr:.4f} vs LGB {roc_auc_lgb:.4f})')\n",
        "ax.set_xlabel('FPR')\n",
        "ax.set_ylabel('TPR')\n",
        "savefig(fig, 'roc_comparison.png')\n",
        "plt.close(fig)"
      ],
      "metadata": {
        "id": "mMEz1XljXaJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. Feature importance (LGB) and plot**"
      ],
      "metadata": {
        "id": "mx3bqWJbXs9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fi = pd.Series(best_lgb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print('\\nTop 20 features (LightGBM):')\n",
        "print(fi.head(20))\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "ax = fig.add_subplot(111)\n",
        "topn = fi.head(20)[::-1]\n",
        "ax.barh(topn.index, topn.values)\n",
        "ax.set_title('Top 20 feature importances (LightGBM)')\n",
        "ax.set_xlabel('Importance')\n",
        "savefig(fig, 'feature_importance_top20.png')\n",
        "plt.close(fig)\n"
      ],
      "metadata": {
        "id": "AO2Dkm-5Xw4p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}